{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet, Random, Printf, Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "w2i_f (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i = Dict{String,Int}()\n",
    "unk = get!(w2i, \"<unk>\", 1+length(w2i))\n",
    "w2i_f(w) = get!(w2i, w, 1+length(w2i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnetArray{Float32,N} where N"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atype = Knet.atype()\n",
    "# atype = Array{Float32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readdata (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function readdata(filename)\n",
    "    data = []\n",
    "    lines = readlines(filename)\n",
    "    for line in lines\n",
    "        tag,words = split(lowercase(strip(line)),\" ||| \")\n",
    "        tag = parse(Int,tag) + 1\n",
    "        words = [w2i_f(w) for w in split(words)]\n",
    "        push!(data,(words,tag))\n",
    "    end\n",
    "    \n",
    "    return data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data = readdata(\"./train.txt\")\n",
    "w2i_f(w) = get(w2i, w, unk)\n",
    "tst_data = readdata(\"./test.txt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwords = length(w2i)\n",
    "ntags = 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Embed; w; end\n",
    "\n",
    "function Embed(vocabsize::Int, embedsize::Int)\n",
    "    return Embed(param(1, vocabsize, embedsize, 1, atype=atype))\n",
    "end\n",
    "\n",
    "function (l::Embed)(x)\n",
    "    l.w[:,x,:,:]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define a convolutional layer:\n",
    "struct Conv; w; b; f; p; end\n",
    "function (c::Conv)(x)\n",
    "#     @show(size(x))\n",
    "    dropped=dropout(x,c.p)\n",
    "    conved = conv4(c.w, dropped, padding=(0,1)) .+ c.b\n",
    "#     @show(size(conved))\n",
    "    pooled = pool(conved; window=(size(conved, 1), size(conved, 2))) # global max pooling\n",
    "    c.f.(pooled)\n",
    "end\n",
    "Conv(w1::Int,w2::Int,cx::Int,cy::Int,f=relu;pdrop=0) = Conv(param(w1,w2,cx,cy,atype=atype), param0(1,1,cy,1,atype=atype), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define dense layer:\n",
    "struct Dense; w; b; f; p; end\n",
    "(d::Dense)(x) = d.f.(d.w * mat(dropout(x,d.p)) .+ d.b) # mat reshapes 4-D tensor to 2-D matrix so we can use matmul\n",
    "Dense(i::Int,o::Int,f=relu;pdrop=0) = Dense(param(o,i,atype=atype), param0(o,atype=atype), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a chain of layers\n",
    "struct Chain\n",
    "    layers\n",
    "    Chain(layers...) = new(layers)\n",
    "end\n",
    "function (c::Chain)(x)\n",
    "    if length(x) < WIN_SIZE\n",
    "        for i in 1:WIN_SIZE-length(x)\n",
    "            push!(x,1)\n",
    "        end\n",
    "    end\n",
    "    for l in c.layers\n",
    "        x = l(x)\n",
    "    end\n",
    "    x\n",
    "end\n",
    "(c::Chain)(x,y) = nll(c(x),[y]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMB_SIZE = 64\n",
    "WIN_SIZE = 3\n",
    "FILTER_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain((Embed(P(KnetArray{Float32,4}(1,16580,64,1))), Conv(P(KnetArray{Float32,4}(1,3,64,64)), P(KnetArray{Float32,4}(1,1,64,1)), NNlib.relu, 0.1), Dense(P(KnetArray{Float32,2}(5,64)), P(KnetArray{Float32,1}(5)), identity, 0)))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Chain(Embed(nwords,EMB_SIZE),\n",
    "              Conv(1, WIN_SIZE, EMB_SIZE, FILTER_SIZE,pdrop=0.1),\n",
    "              Dense(FILTER_SIZE,ntags,identity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acc_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function acc_loss(x,y)\n",
    "    scores = model(x)\n",
    "    loss = nll(scores,[y])\n",
    "    accuracy = argmax(scores)[1] == y\n",
    "    return loss, accuracy\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: train loss/sent=1.1496, acc=0.5497, time=64617000000 nanoseconds\n",
      "iter 0: test acc=0.4086\n",
      "iter 1: train loss/sent=0.6800, acc=0.7937, time=30418000000 nanoseconds\n",
      "iter 1: test acc=0.3937\n",
      "iter 2: train loss/sent=0.2924, acc=0.9198, time=32230000000 nanoseconds\n",
      "iter 2: test acc=0.4077\n",
      "iter 3: train loss/sent=0.1098, acc=0.9683, time=32069000000 nanoseconds\n",
      "iter 3: test acc=0.3995\n",
      "\n",
      "Stacktrace:\n",
      " [1] \u001b[1mmap\u001b[22m\u001b[1m(\u001b[22m::getfield(GPUArrays, Symbol(\"##33#34\")){CuArrays.CuArray{Float32,4,Nothing}}, ::Tuple{Base.Slice{Base.OneTo{Int64}},Array{Int64,1},Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}}}\u001b[1m)\u001b[22m at \u001b[1m./tuple.jl:142\u001b[22m\n",
      " [2] \u001b[1m_unsafe_getindex!\u001b[22m\u001b[1m(\u001b[22m::CuArrays.CuArray{Float32,4,Nothing}, ::CuArrays.CuArray{Float32,4,Nothing}, ::Base.Slice{Base.OneTo{Int64}}, ::Array{Int64,1}, ::Vararg{Union{Real, AbstractArray},N} where N\u001b[1m)\u001b[22m at \u001b[1m/home/ec2-user/.julia/packages/GPUArrays/0lvhc/src/indexing.jl:96\u001b[22m\n",
      " [3] \u001b[1mgetindex\u001b[22m\u001b[1m(\u001b[22m::KnetArray{Float32,4}, ::Function, ::Array{Int64,1}, ::Function, ::Function\u001b[1m)\u001b[22m at \u001b[1m/home/ec2-user/.julia/packages/Knet/HRYiN/src/cuarray.jl:28\u001b[22m\n",
      " [4] \u001b[1m#forw#1\u001b[22m\u001b[1m(\u001b[22m::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::typeof(AutoGrad.forw), ::Function, ::Param{KnetArray{Float32,4}}, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m at \u001b[1m/home/ec2-user/.julia/packages/AutoGrad/pTNVv/src/core.jl:66\u001b[22m\n",
      " [5] \u001b[1mforw\u001b[22m at \u001b[1m/home/ec2-user/.julia/packages/AutoGrad/pTNVv/src/core.jl:65\u001b[22m [inlined]\n",
      " [6] \u001b[1mgetindex\u001b[22m\u001b[1m(\u001b[22m::Param{KnetArray{Float32,4}}, ::Function, ::Array{Int64,1}, ::Function, ::Function\u001b[1m)\u001b[22m at \u001b[1m./none:0\u001b[22m\n",
      " [7] \u001b[1m(::Embed)\u001b[22m\u001b[1m(\u001b[22m::Array{Int64,1}\u001b[1m)\u001b[22m at \u001b[1m./In[7]:8\u001b[22m\n",
      " [8] \u001b[1m(::Chain)\u001b[22m\u001b[1m(\u001b[22m::Array{Int64,1}\u001b[1m)\u001b[22m at \u001b[1m./In[10]:13\u001b[22m\n",
      " [9] \u001b[1m(::Chain)\u001b[22m\u001b[1m(\u001b[22m::Array{Int64,1}, ::Int64\u001b[1m)\u001b[22m at \u001b[1m./In[10]:17\u001b[22m\n",
      " [10] \u001b[1m(::getfield(Knet, Symbol(\"##695#696\")){Knet.Minimize{Array{Any,1}},Tuple{Array{Int64,1},Int64}})\u001b[22m\u001b[1m(\u001b[22m\u001b[1m)\u001b[22m at \u001b[1m/home/ec2-user/.julia/packages/AutoGrad/pTNVv/src/core.jl:205\u001b[22m\n",
      " [11] \u001b[1m#differentiate#3\u001b[22m\u001b[1m(\u001b[22m::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::typeof(AutoGrad.differentiate), ::Function\u001b[1m)\u001b[22m at \u001b[1m/home/ec2-user/.julia/packages/AutoGrad/pTNVv/src/core.jl:144\u001b[22m\n",
      " [12] \u001b[1mdifferentiate\u001b[22m at \u001b[1m/home/ec2-user/.julia/packages/AutoGrad/pTNVv/src/core.jl:135\u001b[22m [inlined]\n",
      " [13] \u001b[1miterate\u001b[22m\u001b[1m(\u001b[22m::Knet.Minimize{Array{Any,1}}, ::Int64\u001b[1m)\u001b[22m at \u001b[1m/home/ec2-user/.julia/packages/Knet/HRYiN/src/train.jl:23\u001b[22m\n",
      " [14] \u001b[1m#adam!#804\u001b[22m\u001b[1m(\u001b[22m::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::typeof(adam!), ::Chain, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m at \u001b[1m/home/ec2-user/.julia/packages/Knet/HRYiN/src/update.jl:409\u001b[22m\n",
      " [15] \u001b[1madam!\u001b[22m\u001b[1m(\u001b[22m::Chain, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m at \u001b[1m/home/ec2-user/.julia/packages/Knet/HRYiN/src/update.jl:409\u001b[22m\n",
      " [16] top-level scope at \u001b[1mIn[14]:3\u001b[22m\n",
      " [17] \u001b[1meval\u001b[22m at \u001b[1m./boot.jl:330\u001b[22m [inlined]\n",
      " [18] \u001b[1msoftscope_include_string\u001b[22m\u001b[1m(\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m at \u001b[1m/home/ec2-user/.julia/packages/SoftGlobalScope/cSbw5/src/SoftGlobalScope.jl:218\u001b[22m\n",
      " [19] \u001b[1mexecute_request\u001b[22m\u001b[1m(\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m at \u001b[1m/home/ec2-user/.julia/packages/IJulia/F1GUo/src/execute_request.jl:67\u001b[22m\n",
      " [20] \u001b[1m#invokelatest#1\u001b[22m at \u001b[1m./essentials.jl:790\u001b[22m [inlined]\n",
      " [21] \u001b[1minvokelatest\u001b[22m at \u001b[1m./essentials.jl:789\u001b[22m [inlined]\n",
      " [22] \u001b[1meventloop\u001b[22m\u001b[1m(\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m at \u001b[1m/home/ec2-user/.julia/packages/IJulia/F1GUo/src/eventloop.jl:8\u001b[22m\n",
      " [23] \u001b[1m(::getfield(IJulia, Symbol(\"##15#18\")))\u001b[22m\u001b[1m(\u001b[22m\u001b[1m)\u001b[22m at \u001b[1m./task.jl:268\u001b[22m\n"
     ]
    },
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] #differentiate#3(::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::typeof(AutoGrad.differentiate), ::Function) at /home/ec2-user/.julia/packages/AutoGrad/pTNVv/src/core.jl:148",
      " [2] differentiate at /home/ec2-user/.julia/packages/AutoGrad/pTNVv/src/core.jl:135 [inlined]",
      " [3] iterate(::Knet.Minimize{Array{Any,1}}, ::Int64) at /home/ec2-user/.julia/packages/Knet/HRYiN/src/train.jl:23",
      " [4] #adam!#804(::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::typeof(adam!), ::Chain, ::Vararg{Any,N} where N) at /home/ec2-user/.julia/packages/Knet/HRYiN/src/update.jl:409",
      " [5] adam!(::Chain, ::Vararg{Any,N} where N) at /home/ec2-user/.julia/packages/Knet/HRYiN/src/update.jl:409",
      " [6] top-level scope at In[14]:3"
     ]
    }
   ],
   "source": [
    "t = Time(now())\n",
    "for i in 1:10    \n",
    "    adam!(model,shuffle(trn_data))\n",
    "    trn_lss_acc = [acc_loss(x...) for x in trn_data]\n",
    "    trn_loss = sum([i[1] for i in trn_lss_acc])/length(trn_data)\n",
    "    trn_acc =sum([i[2] for i in trn_lss_acc])/length(trn_data)\n",
    "\n",
    "    tst_lss_acc = [acc_loss(x...) for x in tst_data]\n",
    "    tst_loss = sum([i[1] for i in tst_lss_acc])/length(tst_data)\n",
    "    tst_acc =sum([i[2] for i in tst_lss_acc])/length(tst_data)\n",
    "    \n",
    "    @printf(\"iter %d: train loss/sent=%.4f, acc=%.4f, time=%s\\n\",i-1,trn_loss,trn_acc,Time(now())-t)\n",
    "    @printf(\"iter %d: test acc=%.4f\\n\",i-1,tst_acc)\n",
    "    t = Time(now())\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
