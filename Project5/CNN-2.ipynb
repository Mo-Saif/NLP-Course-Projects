{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet, Random, Printf, Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "w2i_f (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i = Dict{String,Int}()\n",
    "unk = get!(w2i, \"<unk>\", 1+length(w2i))\n",
    "w2i_f(w) = get!(w2i, w, 1+length(w2i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnetArray{Float32,N} where N"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atype = Knet.atype()\n",
    "# atype = Array{Float32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readdata (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function readdata(filename)\n",
    "    data = []\n",
    "    lines = readlines(filename)\n",
    "    for line in lines\n",
    "        tag,words = split(lowercase(strip(line)),\" ||| \")\n",
    "        tag = parse(Int,tag) + 1\n",
    "        words = [w2i_f(w) for w in split(words)]\n",
    "        push!(data,(words,tag))\n",
    "    end\n",
    "    \n",
    "    return data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data = readdata(\"./train.txt\")\n",
    "w2i_f(w) = get(w2i, w, unk)\n",
    "tst_data = readdata(\"./test.txt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwords = length(w2i)\n",
    "ntags = 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Embed; w; end\n",
    "\n",
    "function Embed(vocabsize::Int, embedsize::Int)\n",
    "    return Embed(param(1, vocabsize, embedsize, 1, atype=atype))\n",
    "end\n",
    "\n",
    "function (l::Embed)(x)\n",
    "    l.w[:,x,:,:]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define a convolutional layer:\n",
    "struct Conv; w; b; f; p; end\n",
    "function (c::Conv)(x)\n",
    "#     @show(size(x))\n",
    "    dropped=dropout(x,c.p)\n",
    "    conved = conv4(c.w, dropped, padding=(0,1)) .+ c.b\n",
    "#     @show(size(conved))\n",
    "    pooled = pool(conved; window=(size(conved, 1), size(conved, 2))) # global max pooling\n",
    "    c.f.(pooled)\n",
    "end\n",
    "Conv(w1::Int,w2::Int,cx::Int,cy::Int,f=relu;pdrop=0) = Conv(param(w1,w2,cx,cy,atype=atype), param0(1,1,cy,1,atype=atype), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define dense layer:\n",
    "struct Dense; w; b; f; p; end\n",
    "(d::Dense)(x) = d.f.(d.w * mat(dropout(x,d.p)) .+ d.b) # mat reshapes 4-D tensor to 2-D matrix so we can use matmul\n",
    "Dense(i::Int,o::Int,f=relu;pdrop=0) = Dense(param(o,i,atype=atype), param0(o,atype=atype), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a chain of layers\n",
    "struct Chain\n",
    "    layers\n",
    "    Chain(layers...) = new(layers)\n",
    "end\n",
    "function (c::Chain)(x)\n",
    "    if length(x) < WIN_SIZE\n",
    "        for i in 1:WIN_SIZE-length(x)\n",
    "            push!(x,1)\n",
    "        end\n",
    "    end\n",
    "    for l in c.layers\n",
    "        x = l(x)\n",
    "    end\n",
    "    x\n",
    "end\n",
    "(c::Chain)(x,y) = nll(c(x),[y]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMB_SIZE = 64\n",
    "WIN_SIZE = 3\n",
    "FILTER_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain((Embed(P(KnetArray{Float32,4}(1,16580,64,1))), Conv(P(KnetArray{Float32,4}(1,3,64,64)), P(KnetArray{Float32,4}(1,1,64,1)), NNlib.relu, 0.1), Dense(P(KnetArray{Float32,2}(5,64)), P(KnetArray{Float32,1}(5)), identity, 0)))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Chain(Embed(nwords,EMB_SIZE),\n",
    "              Conv(1, WIN_SIZE, EMB_SIZE, FILTER_SIZE,pdrop=0.1),\n",
    "              Dense(FILTER_SIZE,ntags,identity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acc_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function acc_loss(x,y)\n",
    "    scores = model(x)\n",
    "    loss = nll(scores,[y])\n",
    "    accuracy = argmax(scores)[1] == y\n",
    "    return loss, accuracy\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: train loss/sent=1.1496, acc=0.5497, time=64617000000 nanoseconds\n",
      "iter 0: test acc=0.4086\n",
      "iter 1: train loss/sent=0.6800, acc=0.7937, time=30418000000 nanoseconds\n",
      "iter 1: test acc=0.3937\n",
      "iter 2: train loss/sent=0.2924, acc=0.9198, time=32230000000 nanoseconds\n",
      "iter 2: test acc=0.4077\n",
      "iter 3: train loss/sent=0.1098, acc=0.9683, time=32069000000 nanoseconds\n",
      "iter 3: test acc=0.3995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = Time(now())\n",
    "for i in 1:10    \n",
    "    adam!(model,shuffle(trn_data))\n",
    "    trn_lss_acc = [acc_loss(x...) for x in trn_data]\n",
    "    trn_loss = sum([i[1] for i in trn_lss_acc])/length(trn_data)\n",
    "    trn_acc =sum([i[2] for i in trn_lss_acc])/length(trn_data)\n",
    "\n",
    "    tst_lss_acc = [acc_loss(x...) for x in tst_data]\n",
    "    tst_loss = sum([i[1] for i in tst_lss_acc])/length(tst_data)\n",
    "    tst_acc =sum([i[2] for i in tst_lss_acc])/length(tst_data)\n",
    "    \n",
    "    @printf(\"iter %d: train loss/sent=%.4f, acc=%.4f, time=%s\\n\",i-1,trn_loss,trn_acc,Time(now())-t)\n",
    "    @printf(\"iter %d: test acc=%.4f\\n\",i-1,tst_acc)\n",
    "    t = Time(now())\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
